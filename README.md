# An√°lisis de Sentimientos en Tweets (Sentiment140)

![Twitter Banner](https://user-images.githubusercontent.com/8160766/225615671-59a0145c-5e4c-443b-8106-6136e38b3017.png) ## üìù Descripci√≥n del Proyecto

Este proyecto se enfoca en el **Procesamiento de Lenguaje Natural (PLN)** para realizar un an√°lisis de sentimientos sobre un conjunto de datos de 1.6 millones de tweets extra√≠dos de la API de Twitter. El objetivo es construir y evaluar modelos de Machine Learning capaces de clasificar los tweets como **positivos** o **negativos**.

A trav√©s de un riguroso preprocesamiento de texto y la aplicaci√≥n de algoritmos de clasificaci√≥n, este an√°lisis busca no solo predecir el sentimiento, sino tambi√©n comparar el rendimiento de diferentes modelos para esta tarea.

## üéØ Objetivos

- Aplicar t√©cnicas de limpieza y preprocesamiento a datos textuales extra√≠dos de redes sociales.
- Generar visualizaciones como gr√°ficos de distribuci√≥n y nubes de palabras para un an√°lisis exploratorio inicial.
- Vectorizar el texto utilizando la t√©cnica **TF-IDF**.
- Entrenar, evaluar y comparar dos modelos de clasificaci√≥n: **Regresi√≥n Log√≠stica** y **Random Forest**.
- Probar los modelos entrenados con texto nuevo para validar su capacidad de generalizaci√≥n.

## üõ†Ô∏è Herramientas y Librer√≠as

* **Lenguaje:** Python 3.x
* **An√°lisis y Manipulaci√≥n de Datos:**
    * **Pandas:** Para la carga y manipulaci√≥n del dataset.
* **Procesamiento de Texto y PLN:**
    * **NLTK:** Para la eliminaci√≥n de *stopwords*.
    * **re (Expresiones Regulares):** Para la limpieza de texto (URLs, n√∫meros, puntuaci√≥n).
    * **Scikit-learn:** Para la vectorizaci√≥n TF-IDF y el entrenamiento de modelos de Machine Learning.
* **Visualizaci√≥n de Datos:**
    * **Matplotlib & Seaborn:** Para generar gr√°ficos de distribuci√≥n y matrices de confusi√≥n.
    * **WordCloud:** Para crear nubes de palabras representativas de cada sentimiento.
* **Entorno de Desarrollo:** Google Colab / Jupyter Notebook

## üìÇ Estructura del Repositorio

```
.
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ training.1600000.processed.noemoticon.csv   # Dataset original de Kaggle
‚îú‚îÄ‚îÄ üìÅ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ proyecto_pln_sentimientos.ipynb             # Notebook con el c√≥digo y an√°lisis
‚îî‚îÄ‚îÄ README.md                                       # Este archivo
```

## üî¨ Metodolog√≠a de An√°lisis

1.  **Carga y Exploraci√≥n de Datos:** Se carg√≥ el dataset `Sentiment140` y se realiz√≥ una exploraci√≥n inicial para entender su estructura y la distribuci√≥n de las clases (positiva y negativa).

2.  **Limpieza y Preprocesamiento de Texto:**
    * Se eliminaron columnas innecesarias, manteniendo solo el texto y el sentimiento (`target`).
    * Se aplic√≥ una funci√≥n de limpieza a cada tweet para:
        * Convertir el texto a min√∫sculas.
        * Remover URLs, n√∫meros y signos de puntuaci√≥n.
        * Eliminar *stopwords* en ingl√©s para reducir el ruido.

3.  **An√°lisis Exploratorio y Visualizaci√≥n:**
    * Se grafic√≥ la distribuci√≥n balanceada de los sentimientos.
    * Se generaron **nubes de palabras** para los tweets positivos y negativos, identificando visualmente los t√©rminos m√°s frecuentes en cada categor√≠a.

4.  **Vectorizaci√≥n TF-IDF:** El texto limpio fue transformado en una representaci√≥n num√©rica utilizando `TfidfVectorizer`. Se eligi√≥ TF-IDF porque penaliza las palabras que son comunes en todos los documentos, dando m√°s importancia a los t√©rminos que son distintivos de un sentimiento en particular.

5.  **Entrenamiento y Evaluaci√≥n de Modelos:**
    * **Modelo 1: Regresi√≥n Log√≠stica:**
        * Se entren√≥ un modelo de Regresi√≥n Log√≠stica como baseline por su eficiencia y buena interpretabilidad.
        * El modelo alcanz√≥ una **precisi√≥n (accuracy) del 78%**.
    * **Modelo 2: Random Forest:**https://github.com/RubenPalma1108/An-lisis-de-Sentimientos-en-Tweets/tree/main
        * Se entren√≥ un clasificador Random Forest para explorar un modelo basado en ensambles.
        * El modelo obtuvo una **precisi√≥n del 71%**, mostrando un rendimiento ligeramente inferior al de la Regresi√≥n Log√≠stica en este caso.

## üìä Resultados y Conclusiones

| Modelo | Precisi√≥n (Accuracy) | Conclusiones Clave |
| :--- | :---: | :--- |
| **Regresi√≥n Log√≠stica** | **78%** | Modelo r√°pido, eficiente y con un rendimiento superior para este dataset. Es una excelente opci√≥n como punto de partida. |
| **Random Forest** | **71%** | Aunque robusto, su rendimiento fue menor. Posiblemente requiere un ajuste m√°s fino de hiperpar√°metros o una mayor profundidad en los √°rboles. |

- La **Regresi√≥n Log√≠stica** demostr√≥ ser el modelo m√°s efectivo y eficiente para esta tarea de clasificaci√≥n de texto.
- Las nubes de palabras revelaron t√©rminos claramente asociados a cada sentimiento, como "love", "good", "happy" para los positivos, y "sad", "miss", "sorry" para los negativos.
- Ambos modelos fueron capaces de predecir correctamente el sentimiento de tweets nuevos escritos manualmente, validando su aplicaci√≥n pr√°ctica.

## üöÄ C√≥mo Ejecutar este Proyecto

1.  Clona este repositorio:
    ```bash
    git clone [https://github.com/tu-usuario/nombre-del-repositorio.git](https://github.com/tu-usuario/nombre-del-repositorio.git)
    ```
2.  Navega al directorio del proyecto:
    ```bash
    cd nombre-del-repositorio
    ```
3.  Instala las dependencias necesarias:
    ```bash
    pip install pandas scikit-learn nltk matplotlib seaborn wordcloud
    ```
4.  Abre el notebook `proyecto_pln_sentimientos.ipynb` en Jupyter o Google Colab para ver el an√°lisis completo y ejecutar el c√≥digo.

## ‚úíÔ∏è Autor

* **[Tu Nombre]** - [Tu Perfil de LinkedIn o GitHub]
